Using parameter file /users/rdscher/CLASS/cs491/HPL/hopper/gcc-11/param_sweep/HPL_params.csv
Using template file /users/rdscher/CLASS/cs491/HPL/hopper/gcc-11/param_sweep/HPL_template.dat
Read param line 2: 336, 8, 8, 125000
Read param BLOCK_SIZE: 336
Read param P_VAL: 8
Read param Q_VAL: 8
Read param N_VAL: 125000
Temp directory: /carc/scratch/users/rdscher/tmp.oyGn2Z4U2B
Created temporary working directory: /carc/scratch/users/rdscher/tmp.oyGn2Z4U2B/2
Now running in /carc/scratch/users/rdscher/tmp.oyGn2Z4U2B/2
Running xhpl in /carc/scratch/users/rdscher/tmp.oyGn2Z4U2B/2...
To request GPUs, add --gpus-per-node X or --gpus X, where X is the desired number of GPUs.
Job 2486582 running on hopper[009-010]
HPL ERROR from process # 44, on line 247 of function HPL_pdpanel_init:
>>> Memory allocation failed <<< Abort ...

HPL ERROR from process # 51, on line 247 of function HPL_pdpanel_init:
>>> Memory allocation failed <<< Abort ...

--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 51 in communicator MPI_COMM_WORLD
with errorcode -1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
--------------------------------------------------------------------------
MPI_ABORT was invoked on rank 44 in communicator MPI_COMM_WORLD
with errorcode -1.

NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.
You may or may not see output from other processes, depending on
exactly when Open MPI kills them.
--------------------------------------------------------------------------
slurmstepd: error: xgetaddrinfo: getaddrinfo(hopper-sn:6817) failed: System error: Device or resource busy
slurmstepd: error: slurm_set_addr: Unable to resolve "hopper-sn"
slurmstepd: error: Detected 1 oom_kill event in StepId=2486582.0. Some of the step tasks have been OOM Killed.
srun: error: hopper010: task 33: Out Of Memory
[hopper010:961101] *** An error occurred in MPI_Send
[hopper010:961101] *** reported by process [4046848000,35]
[hopper010:961101] *** on communicator MPI COMMUNICATOR 5 SPLIT FROM 3
[hopper010:961101] *** MPI_ERR_OTHER: known error not in list
[hopper010:961101] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[hopper010:961101] ***    and potentially your MPI job)
[hopper010:961102] *** An error occurred in MPI_Send
[hopper010:961102] *** reported by process [4046848000,36]
[hopper010:961102] *** on communicator MPI COMMUNICATOR 5 SPLIT FROM 3
[hopper010:961102] *** MPI_ERR_OTHER: known error not in list
[hopper010:961102] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[hopper010:961102] ***    and potentially your MPI job)
slurmstepd: error: xgetaddrinfo: getaddrinfo(hopper-sn:6817) failed: System error: Device or resource busy
slurmstepd: error: slurm_set_addr: Unable to resolve "hopper-sn"
slurmstepd: error: xgetaddrinfo: getaddrinfo(hopper-sn:6817) failed: System error: Device or resource busy
slurmstepd: error: slurm_set_addr: Unable to resolve "hopper-sn"
[hopper010:961126] *** An error occurred in MPI_Send
[hopper010:961126] *** reported by process [4046848000,60]
[hopper010:961126] *** on communicator MPI COMMUNICATOR 5 SPLIT FROM 3
[hopper010:961126] *** MPI_ERR_OTHER: known error not in list
[hopper010:961126] *** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
[hopper010:961126] ***    and potentially your MPI job)
slurmstepd: error: xgetaddrinfo: getaddrinfo(hopper-sn:6817) failed: System error: Device or resource busy
slurmstepd: error: slurm_set_addr: Unable to resolve "hopper-sn"
slurmstepd: error: xgetaddrinfo: getaddrinfo(hopper-sn:6817) failed: System error: Device or resource busy
slurmstepd: error: slurm_set_addr: Unable to resolve "hopper-sn"
slurmstepd: error: *** STEP 2486582.0 ON hopper009 CANCELLED AT 2024-05-03T21:23:21 DUE TO TIME LIMIT ***
slurmstepd: error: *** JOB 2486582 ON hopper009 CANCELLED AT 2024-05-03T21:23:21 DUE TO TIME LIMIT ***
